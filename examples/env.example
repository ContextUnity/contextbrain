# ContextBrain env template (copy to `.env` in your working directory)
#
# Loaded automatically by the CLI via python-dotenv.
#
# Core runtime config (contextbrain core):
CONTEXTBRAIN_CORE_CONFIG_PATH=/abs/path/to/core/settings.toml
#
# Ingestion pipeline config (modules/ingestion/rag):
CONTEXTBRAIN_CONFIG_PATH=/abs/path/to/ingestion/settings.toml
# Alternatively:
# CONTEXTBRAIN_ASSETS_PATH=/abs/path/to/assets
#
# Google / Vertex credentials:
GOOGLE_APPLICATION_CREDENTIALS=/abs/path/to/credentials.json
#
# Vertex (Gemini) configuration:
VERTEX_PROJECT_ID=your-gcp-project
VERTEX_LOCATION=us-central1
#
# NOTE: When contextbrain is embedded as a library, the host may also set:
# - CONTEXTBRAIN_VERTEX_PROJECT_ID
# - CONTEXTBRAIN_VERTEX_LOCATION
#
# Vertex AI mode note:
# ContextBrain sets `GOOGLE_GENAI_USE_VERTEXAI=true` by default to avoid the Google GenAI SDK
# accidentally trying API-key auth. If you need to override this behavior, export
# `GOOGLE_GENAI_USE_VERTEXAI=false` before importing/starting ContextBrain.
#
# Langfuse observability (optional):
LANGFUSE_PUBLIC_KEY=pk_...
LANGFUSE_SECRET_KEY=sk_...
LANGFUSE_HOST=https://cloud.langfuse.com
# LANGFUSE_ENVIRONMENT=develop
# LANGFUSE_SERVICE_NAME=contextbrain

# Postgres retrieval (optional):
POSTGRES_DSN=postgresql+psycopg://USER:PASS@HOST:5432/DBNAME
PGVECTOR_DIM=768
POSTGRES_POOL_MIN_SIZE=2
POSTGRES_POOL_MAX_SIZE=10
POSTGRES_RLS_ENABLED=true

# RAG backend selection:
RAG_PROVIDER=postgres  # or vertex
RAG_BACKEND=postgres   # alias
RAG_EMBEDDINGS_MODEL=hf/sentence-transformers
RAG_KG_BACKEND=postgres  # or file
RAG_TENANT_ID=public
